summary(iris.manhattan)
help(cars)
cars #Investigating the cars dataset.
#Basic numerical EDA for cars dataset.
summary(cars) #Five number summaries.
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
#Basic graphical EDA for cars dataset.
hist(cars$speed, xlab = "Speed in MPH", main = "Histogram of Speed")
hist(cars$dist, xlab = "Distance in Feet", main = "Histogram of Distance")
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2)
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
#Calculating the residual values.
residuals = cars$dist - (beta0 + beta1*cars$speed)
#Note the sum of the residuals is 0.
sum(residuals)
#Visualizing the residuals.
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
#################################################
#####Automatic example with the cars dataset#####
#################################################
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
#conduct the simple linear regression.
summary(model) #All the summary information for the model in question. Reports:
#-The five number summary of the residuals.
#-The coefficient estimates.
#-The coeffiient standard errors.
#-The t-test for significance of the coefficient estimates.
#-The p-values for the significance tests.
#-The level of significance.
#-The RSE and degrees of freedom for the model.
#-The coefficient of determination, R^2.
#-The overall model F-statistic and corresponding p-value.
#The equation of the model can be constructed from the output:
#Predicted Distance = -17.6 + (3.9)*Speed
#The interpretation for the slope coefficient: With a 1 MPH increase in car speed,
#the stopping distance, on average, increases by approximately 3.9 feet.
#The interpretation for the intercept coefficient: When a car's speed is 0 MPH,
#the stopping distance, on average, is -17.6 MPH. Theoretically, does this make
#sense? Why might this be the case?
#The residual standard error is about 15.38; this is an approximation of how much
#the residuas tend to deviate around the regression line.
#The coefficient of determination is about 0.65; approximately 65% of the variability
#in the distance variable is explained by the speed variable.
#The intercept, slope, and overall regression is extremely significant (p-values
#all below 0.05).
#Notice that the F-statistic value for the overall regression is the same as the
#square of the t-statistic value for the speed coefficient:
t.statistic = 9.464
f.statistic = 89.57
t.statistic^2
confint(model) #Creating 95% confidence intervals for the model coefficients.
summary(model) #All the summary information for the model in question. Reports:
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2)
#Constant Variance & Independent Errors
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
abline(h = 0, lty = 2)
#Normality
qqnorm(model$residuals)
qqline(model$residuals)
#Using the built-in plot() function to visualize the residual plots.
plot(model) #Note the addition of the loess smoother and scale-location plot
library(car) #Companion to applied regression.
influencePlot(model)
#####################################
#####Predicting New Observations#####
#####################################
model$fitted.values #Returns the fitted values.
newdata = data.frame(speed = c(15, 20, 25)) #Creating a new data frame to pass
#to the predict() function.
predict(model, newdata, interval = "confidence") #Construct confidence intervals
#for the average value of an
#outcome at a specific point.
predict(model, newdata, interval = "prediction") #Construct prediction invervals
#for a single observation's
install.packages("fpp")
install.packages("forecast")
install.packages("tseries")
################################################
################################################
#####[07] Time Series Analysis Lecture Code#####
################################################
################################################
library(fpp) #Forecasting principles and practice library.
#Example of a trend in a time series.
plot(ustreas, xlab = "Day", ylab = "US treasury bill contracts")
#Example of a treand and seasonality in a time series.
plot(elec, xlab = "Year", ylab = "Australian monthly electricity production")
#Example of a seasonal and cyclical nature in a time series.
plot(hsales, xlab = "Year", ylab = "Monthly housing sales (millions)")
#Example of an irregular nature in a time series.
plot(diff(dj), xlab = "Day", ylab = "Daily change in Dow Jones index")
#Loading the forecast library for time series analysis.
library(forecast)
#Observing the effects of centered moving averages on the Nile dataset.
ylim = c(min(Nile), max(Nile))
plot(Nile, main = "Raw Time Series", ylim = ylim)
plot(ma(Nile, 3), main = "Centered Moving Averages (k = 3)", ylim = ylim)
plot(ma(Nile, 7), main = "Centered Moving Averages (k = 7)", ylim = ylim)
plot(ma(Nile, 15), main = "Centered Moving Averages (k = 15)", ylim = ylim)
plot(Nile, main = "Centered Moving Averages\nNile Data", ylim = ylim)
lines(ma(Nile, 3), col = "red", lwd = 2)
lines(ma(Nile, 7), col = "green", lwd = 2)
lines(ma(Nile, 15), col = "blue", lwd = 2)
legend("bottomleft",
c("Raw Data", "k = 3", "k = 7", "k = 15"),
col = c("black", "red", "green", "blue"),
lwd = c(1, 2, 2, 2))
#Investivating the multiplicative nature of the Airline Passengers dataset.
plot(AirPassengers, main = "Monthly International Airline Passengers")
#Log transforming in order to achieve an additive nature.
log.AirPassengers = log(AirPassengers)
plot(log.AirPassengers, ylab = "Log of Air Passengers",
main = "Monthly International Airline Passengers\nLog Transformed")
#Applying seasonal decomposition; setting s.window to "period" ensures that
#the seasonal effects will be the same across years.
seasonal.decomposition = stl(log.AirPassengers, s.window = "period")
plot(seasonal.decomposition, main = "Seasonal Decomposition of Airline Data")
#The output provides the overall data, the additive seasonal component, the
#additive trend component, and the irregular (remainder) component. The scales
source('~/Dropbox/NYCDSA/Data/Week 04 Data/07 Time Series Analysis Lecture Code.R', echo=TRUE)
#####################################################
#####################################################
#####[06] Generalized Linear Models Lecture Code#####
#####################################################
#####################################################
########################################################
#####Example using Graduate Schools Admissions Data#####
########################################################
GradSchools = read.table("06GraduateSchools.txt")
setwd("~/Dropbox/NYCDSA/Data/Week 04 Data")
GradSchools = read.table("06GraduateSchools.txt")
View(GradSchools)
summary(GradSchools) #Looking at the five number summary information.
sapply(GradSchools, sd) #Looking at the individual standard deviations.
sapply(GradSchools, class) #Looking at the variable classes.
#Notice that the admit variable is being treated as continuous at the moment. What
#does the mean of the admit variable indicate in this scenario? Approximately
#31.75% of the applications in our dataset received acceptances.
table(GradSchools$admit)/nrow(GradSchools) #Manually calculating the proportions.
table(GradSchools$admit, GradSchools$rank) #Checking to see that we have data
#available in all combinations of
#the categorical variables.
plot(GradSchools, col = GradSchools$admit + 2) #Basic graphical EDA.
?plot
GradSchools$rank = as.factor(GradSchools$rank) #Converting the rank variable to
bad.model = lm(admit ~ gre + gpa + rank, data = GradSchools)
summary(bad.model) #Looks like everything is significant, so what's bad?
plot(bad.model) #Severe violations to the assumptions of linear regression.
summary(bad.model$fitted.values)
logit.overall = glm(admit ~ gre + gpa + rank,
family = "binomial",
data = GradSchools)
#Residual plot for logistic regression with an added loess smoother; we would
#hope that, on average, the residual values are 0.
scatter.smooth(logit.overall$fit,
residuals(logit.overall, type = "deviance"),
lpars = list(col = "red"),
xlab = "Fitted Probabilities",
ylab = "Deviance Residual Values",
main = "Residual Plot for\nLogistic Regression of Admission Data")
abline(h = 0, lty = 2)
library(car)
influencePlot(logit.overall) #Can still inspect the influence plot.
summary(logit.overall) #Investigating the overall fit of the model.
exp(logit.overall$coefficients)
cbind("Log Odds" = logit.overall$coefficients,
"Odds" = exp(logit.overall$coefficients))
confint(logit.overall) #For logistic regression objects, the confint() function
#defaults to using the log likelihood to generate confidence
#intervals; this is similar to inverting the likelihood
#ratio test.
confint.default(logit.overall) #To generate confidence intervals for logistic
exp(confint(logit.overall))
exp(confint.default(logit.overall))
#Do the categories for rank add any predictive power to the model? Let's
#conduct the drop in deviance test:
logit.norank = glm(admit ~ gre + gpa,
family = "binomial",
data = GradSchools)
reduced.deviance = logit.norank$deviance #Comparing the deviance of the reduced
reduced.df = logit.norank$df.residual    #model (the one without rank) to...
full.deviance = logit.overall$deviance #...the deviance of the full model (the
full.df = logit.overall$df.residual    #one with the rank terms).
pchisq(reduced.deviance - full.deviance,
reduced.df - full.df,
lower.tail = FALSE)
summary(bad.model) #Looks like everything is significant, so what's bad?
summary(logit.overall) #Investigating the overall fit of the model.
anova(logit.norank, logit.overall, test = "Chisq")
#How does the probability of admission change across ranks for a student
#who has an average GRE and an average GPA?
newdata = with(GradSchools, data.frame(gre = mean(gre),
gpa = mean(gpa),
rank = factor(1:4)))
newdata #Creating a data frame with the average GRE and GPA for each level of
#the rank variable.
predict(logit.overall, newdata) #This gives us the log odds; but we want
#the probabilities.
#Using the formula to convert to probabilities:
exp(predict(logit.overall, newdata))/(1 + exp(predict(logit.overall, newdata)))
#Setting the type to "response" converts the predictions to probabilities for
#us automatically:
predict(logit.overall, newdata, type = "response")
#Making it easier to see the effects of the rank variable by printing out the
#results side-by-side:
cbind(newdata, "Prob. Admitted" = predict(logit.overall, newdata, type = "response"))
#Converting the fitted probabilities to binary:
admitted.predicted = round(logit.overall$fitted.values)
logit.overall$fitted.values
table(truth = GradSchools$admit, prediction = admitted.predicted)
#It seems like this model made a lot of mistakes (116 out of 400)! This is quite
#dreadful in this case. Let's do a little bit more exploring. We never looked at
#the overall test of deviance:
pchisq(logit.overall$deviance, logit.overall$df.residual, lower.tail = FALSE)
1 - logit.overall$deviance/logit.overall$null.deviance
table(GradSchools$admit) #Our data contains 273 unadmitted students and 127
#admitted students.
table(admitted.predicted) #The model we created predicts that 351 students will
#not be admitted, and only 49 will be admitted.
table(truth = GradSchools$admit, prediction = admitted.predicted)
setwd("~/Dropbox/NYCDSA/Homework/20151013 - Generalized Linear Models")
install.packages("Sleuth2")
library(Sleuth2)
data(case2002)
data("case2002")
library(Sleuth2)
data("case2002")
View(case2002)
data(case2002)
data("case2002")
data <- case2002
head(data)
summary(data)
sapplly(data, sd)
sapply(data, sd)
sapply(data, class)
cancer <- case2002
head(cancer)
summary(cancer)
sapply(cancer, sd)
sapply(cancer, class)
table(cancer$LC)/nrow(cancer)
plot(cancer, col = cancer$LC)
View(cancer)
head(cancer)
plot(cancer$LC, cancer$AG + cancer$YR + cancer$CD, col = cancer$LC)
plot(cancer$AG + cancer$YR + cancer$CD, col = cancer$LC)
plot(cancer$AG ~ cancer$YR ~ cancer$CD, col = cancer$LC)
plot(cancer, col = cancer$LC)
model.all <- glm(LC ~ FM + SS + BK + AG + YR + CD, family = "binomial", data = cancer)
summary(model.all)
plot(model.all)
influencePlot(model.all)
scatter.smooth(model.all$fit,
residuals(model.all, type = "deviance"),
lpars = list(col = "red"),
xlab = "Fitted Probabilities",
ylab = "Deviance Residual Values",
main = "Residual Plot for\nLogistic Regression of Lung Cancer Data")
abline(h = 0, lty = 2)
influencePlot(model.all)
pchisq(model.all$deviance, model.all$$df.residual, lower.tail = FALSE)
pchisq(model.all$deviance, model.all$df.residual, lower.tail = FALSE)
summary(model.all)
model.all$coef
summary(model.all)
exp(model.all$coefficients)
summary(cancer)
confint(model.all)
confint.default(model.all)
exp(confint.default(model.all))
model.xBK <- glm(LC ~ FM + SS + AG + YR + CD, family = "binomial", data = cancer)
summary(model.xBK)
summary(model.all)
pchisq(model.xBK$deviance, model.xBK$df.residual, lower.tail = FALSE)
reduced.deviance <- model.xBK$deviance
reduced.df <- model.xBK$df.residual
full.deviance <- model.all$deviance
full.df <- model.all$df.residual
pchisq(reduced.deviance - full.deviance, reduced.df - full.df, lower.tail = FALSE)
model.BKYR <- glm(LC ~ BK + YR, family = "binomial", data = cancer)
summary(model.BKYR)
summary(model.all)
summary(model.BKYR)
reduced.deviance <- model.BKYR$deviance
reduced.df <- model.BKYR$df.residual
full.deviance <- model.all$deviance
full.df <- model.all$df.residual
pchisq(reduced.deviance - full.deviance, reduced.df - full.df, lower.tail = FALSE)
AIC(model.all, model.xBK, model.BKYR)
BIC(model.all, model.xBK, model.BKYR)
#####################################################
#####################################################
#####[06] Generalized Linear Models Lecture Code#####
#####################################################
#####################################################
########################################################
#####Example using Graduate Schools Admissions Data#####
########################################################
GradSchools = read.table("06GraduateSchools.txt")
head(GradSchools)
#Variables in the dataset:
#-Admit: A binary variable indicating whether or not a student was admitted to
#        the graduate school.
#-GRE: A continuous variable indicating a student's score on the GRE.
#-GPA: A contunuous variable indicating a student's undergraduate grade point
#      average.
#-Rank: A categorical variable indicating the level of prestige of a school; 1
#       indicates the highest prestige, 4 indicates the lowest prestige.
summary(GradSchools) #Looking at the five number summary information.
sapply(GradSchools, sd) #Looking at the individual standard deviations.
sapply(GradSchools, class) #Looking at the variable classes.
#Notice that the admit variable is being treated as continuous at the moment. What
#does the mean of the admit variable indicate in this scenario? Approximately
#31.75% of the applications in our dataset received acceptances.
table(GradSchools$admit)/nrow(GradSchools) #Manually calculating the proportions.
table(GradSchools$admit, GradSchools$rank) #Checking to see that we have data
#available in all combinations of
#the categorical variables.
plot(GradSchools, col = GradSchools$admit + 2) #Basic graphical EDA.
GradSchools$rank = as.factor(GradSchools$rank) #Converting the rank variable to
#a categorical variable.
#Being naive at first and fitting a multiple linear regression model.
bad.model = lm(admit ~ gre + gpa + rank, data = GradSchools)
summary(bad.model) #Looks like everything is significant, so what's bad?
plot(bad.model) #Severe violations to the assumptions of linear regression.
summary(bad.model$fitted.values)
#Fitting the logistic regression with all variables; the family parameter
#specifies the error distribution and link function to be used. For logistic
#regression, this is binomial.
logit.overall = glm(admit ~ gre + gpa + rank,
family = "binomial",
data = GradSchools)
#Residual plot for logistic regression with an added loess smoother; we would
#hope that, on average, the residual values are 0.
scatter.smooth(logit.overall$fit,
residuals(logit.overall, type = "deviance"),
lpars = list(col = "red"),
xlab = "Fitted Probabilities",
ylab = "Deviance Residual Values",
main = "Residual Plot for\nLogistic Regression of Admission Data")
abline(h = 0, lty = 2)
library(car)
influencePlot(logit.overall) #Can still inspect the influence plot.
summary(logit.overall) #Investigating the overall fit of the model.
#Coefficient interpretations on the log odds scale:
#-Intercept: The log odds of a student getting admitted to a graduate school
#            when they attended a top tier undergraduate school and received a
#            0 on the GRE and a 0 as their GPA is approximately -3.990.
#-GRE: For every additional point a student scores on the GRE, their log odds
#      of being admitted to graduate school increase by approximately 0.002,
#      holding all other variables constant.
#-GPA: For every additional point a student raises their GPA, their log odds of
#      being admitted to graduate school increase by approximately 0.804, holding
#      all other variables constant.
#-Rank: The change in log odds associated with attending an undergraduate school
#       with prestige of rank 2, 3, and 4, as compared to a school with prestige
#       rank 1, is approximately -0.675, -1.340, and -1.552, respectively, holding
#       all other variables constant.
exp(logit.overall$coefficients)
#Coefficient interpretations on the odds scale:
#-Intercept: The odds of a student getting admitted to a graduate school
#            when they attended a top tier undergraduate school and received a
#            0 on the GRE and a 0 as their GPA is approximately 0.019.
#-GRE: For every additional point a student scores on the GRE, their odds
#      of being admitted to graduate school multiply by approximately 1.002,
#      holding all other variables constant.
#-GPA: For every additional point a student raises their GPA, their odds of
#      being admitted to graduate school multiply by approximately 2.235, holding
#      all other variables constant.
#-Rank: The multiplicative change odds associated with attending an undergraduate school
#       with prestige of rank 2, 3, and 4, as compared to a school with prestige
#       rank 1, is approximately 0.509, 0.262, and 0.212, respectively, holding
#       all other variables constant.
#Inspecting the relationship between log odds and odds.
cbind("Log Odds" = logit.overall$coefficients,
"Odds" = exp(logit.overall$coefficients))
confint(logit.overall) #For logistic regression objects, the confint() function
#defaults to using the log likelihood to generate confidence
#intervals; this is similar to inverting the likelihood
#ratio test.
confint.default(logit.overall) #To generate confidence intervals for logistic
#regression models based on the standard errors
#as we are accustomed to, we can use the
#confint.default() function.
#Generating confidence intervals for the coefficients on the odds scale.
exp(confint(logit.overall))
exp(confint.default(logit.overall))
#Do the categories for rank add any predictive power to the model? Let's
#conduct the drop in deviance test:
logit.norank = glm(admit ~ gre + gpa,
family = "binomial",
data = GradSchools)
reduced.deviance = logit.norank$deviance #Comparing the deviance of the reduced
reduced.df = logit.norank$df.residual    #model (the one without rank) to...
full.deviance = logit.overall$deviance #...the deviance of the full model (the
full.df = logit.overall$df.residual    #one with the rank terms).
pchisq(reduced.deviance - full.deviance,
reduced.df - full.df,
lower.tail = FALSE)
#The p-value is extremely small (<.0005); we have evidence to conclude that the
#model with the factors for rank is preferable to the model without the factors
#for rank.
#More simply, we can use the anova() function and set the test to "Chisq".
anova(logit.norank, logit.overall, test = "Chisq")
#How does the probability of admission change across ranks for a student
#who has an average GRE and an average GPA?
newdata = with(GradSchools, data.frame(gre = mean(gre),
gpa = mean(gpa),
rank = factor(1:4)))
newdata #Creating a data frame with the average GRE and GPA for each level of
#the rank variable.
predict(logit.overall, newdata) #This gives us the log odds; but we want
#the probabilities.
#Using the formula to convert to probabilities:
exp(predict(logit.overall, newdata))/(1 + exp(predict(logit.overall, newdata)))
#Setting the type to "response" converts the predictions to probabilities for
#us automatically:
predict(logit.overall, newdata, type = "response")
#Making it easier to see the effects of the rank variable by printing out the
#results side-by-side:
cbind(newdata, "Prob. Admitted" = predict(logit.overall, newdata, type = "response"))
#Converting the fitted probabilities to binary:
admitted.predicted = round(logit.overall$fitted.values)
#Comparing the true values to the predicted values:
table(truth = GradSchools$admit, prediction = admitted.predicted)
#It seems like this model made a lot of mistakes (116 out of 400)! This is quite
#dreadful in this case. Let's do a little bit more exploring. We never looked at
#the overall test of deviance:
pchisq(logit.overall$deviance, logit.overall$df.residual, lower.tail = FALSE)
#The p-value for the overall test of deviance is <.05, indicating that this model
#is not a good overall fit!
#What about checking the McFadden's pseudo R^2 based on the deviance?
1 - logit.overall$deviance/logit.overall$null.deviance
#Only about 8.29% of the variability in admission appears to be explained by
#the predictors in our model; while the model is valid, it seems as though it
#isn't extremely informative.
#What have we found out? The overall model we created doesn't give us much
#predictive power in determining whether a student will be admitted to
#graduate school.
table(GradSchools$admit) #Our data contains 273 unadmitted students and 127
#admitted students.
table(admitted.predicted) #The model we created predicts that 351 students will
#not be admitted, and only 49 will be admitted.
table(truth = GradSchools$admit, prediction = admitted.predicted)
#The table of the truth against the prediction shows that we only have an accuracy
#of (254 + 30)/400 = 71%; yet, if we were to simply predict "unadmitted" for
#everyone uniformly, we would have an accuracy of 273/400 = 68.25%! No wonder
#why the overall test of deviance was insignificant -- predicting only the
#intercept of the baseline probability was just as sufficient!
paste("Full Model R^2:", 1 - model.full$deviance/model.full$null.deviance)
paste("Excluding Birdkeeping R^2:", 1 - model.xBK$deviance/model.xBK$null.deviance)
paste("Birdkeeping & Years Smoking R^2:", 1 - model.BKYR$deviance/model.BKYR$null.deviance)
paste("Full Model R^2:", 1 - model.full$deviance/model.full$null.deviance)
paste("Full Model R^2:", 1 - model.all$deviance/model.all$null.deviance)
paste("Excluding Birdkeeping R^2:", 1 - model.xBK$deviance/model.xBK$null.deviance)
paste("Birdkeeping & Years Smoking R^2:", 1 - model.BKYR$deviance/model.BKYR$null.deviance)
AIC(model.all, model.xBK, model.BKYR)
BIC(model.all, model.xBK, model.BKYR)
YR = avg(YR)))
newdata = with(cancer, data.frame(BK = factor(1:2), YR = avg(YR)))
newdata = with(cancer, data.frame(BK = factor(1:2), YR = mean(YR)))
View(newdata)
newdata
str(cancer$BK)
predict(model.BKYR, newdata, type = "response")
newdata = with(cancer, data.frame(BK = as.factor("Bird", "NoBird"), YR = mean(YR)))
newdata = with(cancer, data.frame(BK = as.factor("Bird", "NoBird"), YR = mean(YR)))
newdata = with(cancer, data.frame(BK = as.factor("NoBird", "Bird"), YR = mean(YR)))
newdata = with(cancer, data.frame(BK = as.factor(c("NoBird", "Bird"), YR = mean(YR)))
newdata = with(cancer, data.frame(BK = as.factor(c("NoBird", "Bird")), YR = mean(YR)))
newdata = with(cancer, data.frame(BK = as.factor(c("NoBird", "Bird")), YR = mean(YR)))
newdata
predict(model.BKYR, newdata, type = "response")
cbind(newdata, "Prob. Lung Cancer" = predict(model.BKYR, newdata, type = "response"))
newdata = with(cancer, data.frame(BK = as.factor(c("NoBird", "Bird")), YR = 0))
newdata
cbind(newdata, "Prob. Lung Cancer" = predict(model.BKYR, newdata, type = "response"))
LC.predict <- round(model.BKYR$fitted.values)
table(truth = cancer$LC, prediction = LC.predict)
paste("Correctly predicts no lung cancer:", 85/(85+27))
paste("correctly predicts lung cancer:", 22/(22+13))
paste("Correctly predicts no lung cancer:", 85/(85+13))
paste("correctly predicts lung cancer:", 22/(22+27))
(85+22)/147
paste("Correctly predicts no lung cancer:", 85/(85+13))
paste("Correctly predicts lung cancer:", 22/(22+27))
paste("Correct predictions:", (85+22)/147)
paste("correctly predicts lung cancer:", (27+13)/147)
summary(cancer)
49/147
paste("Correctly predicts lung cancer:", 22/(22+27))
paste("Correct predictions:", (85+22)/147)
table(truth = cancer$LC, prediction = LC.predict)
paste("Correctly predicts lung cancer:", 22/(22+27))
?influencePlot
library(car)
cancer <- case2002
