i<-1
#Iterate through the product vector
while (i <= as.numeric(length(prodvector))){
#Set the test variable equal to the current element in the product vector
tst<-prodvector[i]
#Set the reverse variable equal to the reverse of the test variable
#Test variable is converted to a character vector and elements are reversed
rev<-as.numeric(paste(rev(strsplit(as.character(tst),"")[[1]]),collapse=""))
#Check if the reverse variable equals the test variable, if so this is a palindrome
if(tst==rev){
#If a palindrome then store to the palindrome vector
palindrome<- c(palindrome,tst)
}
#Increment the iterator
i<-i+1
}
#Print the largest palindrome
paste("The largest palindrome made from the product of two 3-digit numbers is: ", max(palindrome))
#R Script to find largest palindrome made from the product of two 3-digit numbers
#Joe Eckert
#Disable scientific notation on integers 99 digits or less
options(scipen=99)
#Create a matrix of products of all three digit integers
prodmatrix<-outer(999:100,999:100,"*")
#Convert the product matrix to a vector
prodvector<-as.vector(prodmatrix)
#Sort the product vector in descending order
prodvector<-sort(prodvector,decreasing=TRUE)
#Remove duplicate values from product vector
prodvector<-unique(prodvector)
#Declare palindrome result vector
palindrome<-0
#Set the iterator to 1
i<-1
#Iterate through the product vector
while (i <= as.numeric(length(prodvector))){
#Set the test variable equal to the current element in the product vector
tst<-prodvector[i]
tst
#Set the reverse variable equal to the reverse of the test variable
#Test variable is converted to a character vector and elements are reversed
rev<-as.numeric(paste(rev(strsplit(as.character(tst),"")[[1]]),collapse=""))
#Check if the reverse variable equals the test variable, if so this is a palindrome
if(tst==rev){
#If a palindrome then store to the palindrome vector
palindrome<- c(palindrome,tst)
}
#Increment the iterator
i<-i+1
}
#Print the largest palindrome
paste("The largest palindrome made from the product of two 3-digit numbers is: ", max(palindrome))
#R Script to find the sum of all numbers below 1000 that are divisible by 3 or 5
#Joe Eckert
#Set the iterator to 1
i<-1
#Declare the sum variable
sumofnum<-0
#Iterate through all numbers less than 1000
while (i < 1000){
#Check if the current number is divisible by 3
if(i/3 == floor(i/3)){
#If divisible by 3 add to the sum variable
sumofnum<-sumofnum+i
}else{
#If not divisible by 3 check if the current number is divisible by 5
if(i/5 == floor(i/5)){
#If divisible by 5 add to the sum variable
sumofnum<-sumofnum+i
}
}
#Increment the iterator
i<-i+1
}
#Print the sum
paste("The sum of all numbers below 1000 that are divisible by 3 or 5 is: ", sumofnum)
#R Script to find largest palindrome made from the product of two 3-digit numbers
#Joe Eckert
#Disable scientific notation on integers 99 digits or less
options(scipen=99)
#Create a matrix of products of all three digit integers
prodmatrix<-outer(999:100,999:100,"*")
#Convert the product matrix to a vector
prodvector<-as.vector(prodmatrix)
#Sort the product vector in descending order
prodvector<-sort(prodvector,decreasing=TRUE)
#Remove duplicate values from product vector
prodvector<-unique(prodvector)
#Declare palindrome result vector
palindrome<-0
#Set the iterator to 1
i<-1
#Iterate through the product vector
while (i <= as.numeric(length(prodvector))){
#Set the test variable equal to the current element in the product vector
tst<-prodvector[i]
#Set the reverse variable equal to the reverse of the test variable
#Test variable is converted to a character vector and elements are reversed
rev<-as.numeric(paste(rev(strsplit(as.character(tst),"")[[1]]),collapse=""))
#Check if the reverse variable equals the test variable, if so this is a palindrome
if(tst==rev){
#If a palindrome then store to the palindrome vector
palindrome<- c(palindrome,tst)
}
#Increment the iterator
i<-i+1
}
#Print the largest palindrome
paste("The largest palindrome made from the product of two 3-digit numbers is: ", max(palindrome))
#R Script to find the sum of all numbers below 1000 that are divisible by 3 or 5
#Joe Eckert
#Set the iterator to 1
i<-1
#Declare the sum variable
sumofnum<-0
#Iterate through all numbers less than 1000
while (i < 1000){
#Check if the current number is divisible by 3
if(i/3 == floor(i/3)){
#If divisible by 3 add to the sum variable
sumofnum<-sumofnum+i
}else{
#If not divisible by 3 check if the current number is divisible by 5
if(i/5 == floor(i/5)){
#If divisible by 5 add to the sum variable
sumofnum<-sumofnum+i
}
}
#Increment the iterator
i<-i+1
}
#Print the sum
paste("The sum of all numbers below 1000 that are divisible by 3 or 5 is: ", sumofnum)
#R Script to find the sum of all numbers below 1000 that are divisible by 3 or 5
#Joe Eckert
#Set the iterator to 1
i<-1
#Declare the sum variable
sumofnum<-0
#Iterate through all numbers less than 1000
while (i < 1000){
#Check if the current number is divisible by 3
if(i/3 == floor(i/3)){
#If divisible by 3 add to the sum variable
sumofnum<-sumofnum+i
}else{
#If not divisible by 3 check if the current number is divisible by 5
if(i/5 == floor(i/5)){
#If divisible by 5 add to the sum variable
sumofnum<-sumofnum+i
}
}
#Increment the iterator
i<-i+1
}
#Print the sum
paste("The sum of all numbers below 1000 that are divisible by 3 or 5 is: ", sumofnum)
#R Script to find largest palindrome made from the product of two 3-digit numbers
#Joe Eckert
#Disable scientific notation on integers 99 digits or less
options(scipen=99)
#Create a matrix of products of all three digit integers
prodmatrix<-outer(999:100,999:100,"*")
#Convert the product matrix to a vector
prodvector<-as.vector(prodmatrix)
#Sort the product vector in descending order
prodvector<-sort(prodvector,decreasing=TRUE)
#Remove duplicate values from product vector
prodvector<-unique(prodvector)
#Declare palindrome result vector
palindrome<-0
#Set the iterator to 1
i<-1
#Iterate through the product vector
while (i <= as.numeric(length(prodvector))){
#Set the test variable equal to the current element in the product vector
tst<-prodvector[i]
#Set the reverse variable equal to the reverse of the test variable
#Test variable is converted to a character vector and elements are reversed
rev<-as.numeric(paste(rev(strsplit(as.character(tst),"")[[1]]),collapse=""))
#Check if the reverse variable equals the test variable, if so this is a palindrome
if(tst==rev){
#If a palindrome then store to the palindrome vector
palindrome<- c(palindrome,tst)
}
#Increment the iterator
i<-i+1
}
#Print the largest palindrome
paste("The largest palindrome made from the product of two 3-digit numbers is: ", max(palindrome))
data()
runif(12)
runif(1)
# Load required libraries
library(dplyr)
library(choroplethr)
library(choroplethrMaps)
library(stringr)
# Import data from Federal Home Loan Banks
# http://www.fhfa.gov/DataTools/Downloads/Pages/FHLBank-Public-Use-Database-Previous-Years.aspx
fhlb09 <- read.csv("AMA_PUDB_EXPORT_123109.csv", stringsAsFactors = FALSE)
fhlb10 <- read.csv("AMA_PUDB_EXPORT_123110.csv", stringsAsFactors = FALSE)
fhlb11 <- read.csv("AMA_PUDB_EXPORT_123111.csv", stringsAsFactors = FALSE)
fhlb12 <- read.csv("AMA_PUDB_EXPORT_123112.csv", stringsAsFactors = FALSE)
fhlb13 <- read.csv("AMA_PUDB_EXPORT_123113.csv", stringsAsFactors = FALSE)
fhlb14 <- read.csv("AMA_PUDB_EXPORT_123114.csv", stringsAsFactors = FALSE)
# Import FIPS data
# https://www.census.gov/geo/reference/codes/cou.html
fips <- read.csv("FIPS.txt")
# Import county regions from cholorplethr package
data(df_pop_county)
counties <- df_pop_county
# Correct column names to allow for rbind()
names(fhlb09)[2] <- "Loan.Number"
fhlb09$FHLBankID <- NA
names(fhlb14)[65] <- "Co.Borrower.Credit.Score"
# Bind yearly data sets into a single data frame
fhlb <- rbind(fhlb14, fhlb13, fhlb12, fhlb11, fhlb10, fhlb09)
# Save data frame as Rda file for future loading
save(fhlb, fips, counties, file = "data.Rds")
# Clear working memory
rm(list = ls())
# Load the previously created data frame
load("data.Rds")
# Join state and county data from FIPS to FHLB data
fhlb <- left_join(fhlb, fips, by = c("FIPSStateCode" = "STATEFP", "FIPSCountyCode" = "COUNTYFP"))
# Create region code
fhlb$region <- as.numeric(paste0(fhlb$FIPSStateCode, str_pad(fhlb$FIPSCountyCode, 3, pad = "0")))
####BELOW IS FOR TESTING
### https://cran.r-project.org/web/packages/choroplethr/vignettes/c-county-choropleth.html
# Get average rate by region
fhlbtest <- group_by(fhlb, region)
fhlbtest <- summarise(fhlbtest, avgIntRate = mean(Rate))
## MAP STATISTICS BY STATE _ ZIP IS TOO MUCH
# Merge average interest rate by region to the county data set and map using choropleth
counties$value <- 0
counties <- left_join(counties, fhlbtest, "region" = "region")
counties$value <- NULL
names(counties)[2] <- "value"
county_choropleth(counties)
setwd("~/Dropbox/NYCDSA/Projects/20151009 - Shiny Project")
# Load required libraries
library(dplyr)
library(choroplethr)
library(choroplethrMaps)
library(stringr)
# Import data from Federal Home Loan Banks
# http://www.fhfa.gov/DataTools/Downloads/Pages/FHLBank-Public-Use-Database-Previous-Years.aspx
fhlb09 <- read.csv("AMA_PUDB_EXPORT_123109.csv", stringsAsFactors = FALSE)
fhlb10 <- read.csv("AMA_PUDB_EXPORT_123110.csv", stringsAsFactors = FALSE)
fhlb11 <- read.csv("AMA_PUDB_EXPORT_123111.csv", stringsAsFactors = FALSE)
fhlb12 <- read.csv("AMA_PUDB_EXPORT_123112.csv", stringsAsFactors = FALSE)
fhlb13 <- read.csv("AMA_PUDB_EXPORT_123113.csv", stringsAsFactors = FALSE)
fhlb14 <- read.csv("AMA_PUDB_EXPORT_123114.csv", stringsAsFactors = FALSE)
# Import FIPS data
# https://www.census.gov/geo/reference/codes/cou.html
fips <- read.csv("FIPS.txt")
# Import county regions from cholorplethr package
data(df_pop_county)
counties <- df_pop_county
# Correct column names to allow for rbind()
names(fhlb09)[2] <- "Loan.Number"
fhlb09$FHLBankID <- NA
names(fhlb14)[65] <- "Co.Borrower.Credit.Score"
# Bind yearly data sets into a single data frame
fhlb <- rbind(fhlb14, fhlb13, fhlb12, fhlb11, fhlb10, fhlb09)
# Save data frame as Rda file for future loading
save(fhlb, fips, counties, file = "data.Rds")
# Clear working memory
rm(list = ls())
# Load the previously created data frame
load("data.Rds")
# Join state and county data from FIPS to FHLB data
fhlb <- left_join(fhlb, fips, by = c("FIPSStateCode" = "STATEFP", "FIPSCountyCode" = "COUNTYFP"))
# Create region code
fhlb$region <- as.numeric(paste0(fhlb$FIPSStateCode, str_pad(fhlb$FIPSCountyCode, 3, pad = "0")))
####BELOW IS FOR TESTING
### https://cran.r-project.org/web/packages/choroplethr/vignettes/c-county-choropleth.html
# Get average rate by region
fhlbtest <- group_by(fhlb, region)
fhlbtest <- summarise(fhlbtest, avgIntRate = mean(Rate))
## MAP STATISTICS BY STATE _ ZIP IS TOO MUCH
# Merge average interest rate by region to the county data set and map using choropleth
counties$value <- 0
counties <- left_join(counties, fhlbtest, "region" = "region")
counties$value <- NULL
names(counties)[2] <- "value"
county_choropleth(counties)
install.packages('choroplethr')
install.packages('choroplethrMaps')
# Load required libraries
library(dplyr)
library(choroplethr)
library(choroplethrMaps)
library(stringr)
# Import data from Federal Home Loan Banks
# http://www.fhfa.gov/DataTools/Downloads/Pages/FHLBank-Public-Use-Database-Previous-Years.aspx
fhlb09 <- read.csv("AMA_PUDB_EXPORT_123109.csv", stringsAsFactors = FALSE)
fhlb10 <- read.csv("AMA_PUDB_EXPORT_123110.csv", stringsAsFactors = FALSE)
fhlb11 <- read.csv("AMA_PUDB_EXPORT_123111.csv", stringsAsFactors = FALSE)
fhlb12 <- read.csv("AMA_PUDB_EXPORT_123112.csv", stringsAsFactors = FALSE)
fhlb13 <- read.csv("AMA_PUDB_EXPORT_123113.csv", stringsAsFactors = FALSE)
fhlb14 <- read.csv("AMA_PUDB_EXPORT_123114.csv", stringsAsFactors = FALSE)
# Import FIPS data
# https://www.census.gov/geo/reference/codes/cou.html
fips <- read.csv("FIPS.txt")
# Import county regions from cholorplethr package
data(df_pop_county)
counties <- df_pop_county
# Correct column names to allow for rbind()
names(fhlb09)[2] <- "Loan.Number"
fhlb09$FHLBankID <- NA
names(fhlb14)[65] <- "Co.Borrower.Credit.Score"
# Bind yearly data sets into a single data frame
fhlb <- rbind(fhlb14, fhlb13, fhlb12, fhlb11, fhlb10, fhlb09)
# Save data frame as Rda file for future loading
save(fhlb, fips, counties, file = "data.Rds")
# Clear working memory
rm(list = ls())
# Load the previously created data frame
load("data.Rds")
# Join state and county data from FIPS to FHLB data
fhlb <- left_join(fhlb, fips, by = c("FIPSStateCode" = "STATEFP", "FIPSCountyCode" = "COUNTYFP"))
# Create region code
fhlb$region <- as.numeric(paste0(fhlb$FIPSStateCode, str_pad(fhlb$FIPSCountyCode, 3, pad = "0")))
####BELOW IS FOR TESTING
### https://cran.r-project.org/web/packages/choroplethr/vignettes/c-county-choropleth.html
# Get average rate by region
fhlbtest <- group_by(fhlb, region)
fhlbtest <- summarise(fhlbtest, avgIntRate = mean(Rate))
## MAP STATISTICS BY STATE _ ZIP IS TOO MUCH
# Merge average interest rate by region to the county data set and map using choropleth
counties$value <- 0
counties <- left_join(counties, fhlbtest, "region" = "region")
counties$value <- NULL
names(counties)[2] <- "value"
county_choropleth(counties)
library(MASS)
cats <- cats
plot(cats$Bwt, cats$Hwt, xlab = "Body weight", ylab = "Heart weight", main = "Body weight vs Heart weight")
## Looking at the simple scatter plot it appears that a simple linear regression would be a good fit for this data because as the body weight increases there appears to be a relative increase in the heart weight.
# Question 1.2
catslm <- lm(Hwt ~ Bwt, data = cats)
summary(catslm)
## a - Hwt = 4.03(Hwt) - 0.36
## b - the intercept of -0.36 says that when the body weight is 0 we would expect a heart weight of -0.36, which intuitively does not make sense.  The slope coefficient on body weight is 4.03 means that for an increase of 1kg in body weight the heart weight will increase by 4.03g.
## c - according to the linear model, the intercept coefficient is not significant (p value = .6), however the slope coefficient is highly significant (p value ~0)
## d - the overall linear model is significant as the p value for the F test is less than 0.05.  This relates to part c because the slope coefficient is highly significant
## e - the RSE is 1.452 which is low, indicating that the linear model has a relatively good fit
## f - the coefficient of determination is 64.7%, which means that 64.7% of the varience in heart weight is attributed to body weight
# Question 1.3
abline(catslm, lty = 2, col = "red")
# Question 1.4
resid <- residuals(catslm)
pred <- predict(catslm)
segments(cats$Bwt, cats$Hwt, cats$Bwt, pred, col = "red")
## The residual for the observation with the highest heart weight is abnormally large
# Question 1.5
confint(catslm)
## Confidence interval for the intercept is -1.72 to 1.01 and the confidence interval for the body weight coefficient is 3.54 and 4.53.  Based on the sample data we would assume with 95% confidence that the true coefficient for body weight is between 3.54 and 4.53
# Question 1.6
## Linearity - looking at the original plot of the data from question 1.1 the data appears to have a linear quality.
plot(catslm$fitted, catslm$residuals, xlab = "Fitted Values", ylab = "Residual Values", main = "Residual Plot for Cats")
abline(h = 0, lty = 2, col = "red")
## Constant Variance - For the most part variance appears to be constant, however as heart weight is greater than 14 it appears that the errors are increasing
## Independent Errors - the plot also appears to show that the errors are independent from one another
qqnorm(catslm$residuals)
## Normality - the QQ plot shows a straight line, which means that the error terms are likely drawn from an identical gaussian distribution at each value of the explanatory variable
# Question 1.7
plot(cats$Bwt, cats$Hwt, xlab = "Body weight", ylab = "Heart weight", main = "Body weight vs Heart weight")
abline(catslm, lty = 2, col = "green")
newdata <- data.frame(Bwt = 0:4)
conf.band <- predict(catslm, newdata, interval = "confidence")
pred.band <- predict(catslm, newdata, interval = "predict")
lines(newdata$Bwt, conf.band[,2], col = "blue")
lines(newdata$Bwt, conf.band[,3], col = "blue")
lines(newdata$Bwt, pred.band[,2], col = "red")
lines(newdata$Bwt, pred.band[,3], col = "red")
legend("topleft", c("Regression Line", "Conf. Band", "Pred Band"), lty = c(2, 1), col = c("green", "blue", "red"))
## The confidence interval shows where you would expect the true mean of the data to be.  The predicition interval shows where you would expect future observations to show up when randomly sampling the population.  Because the confidence mean is based on the mean it is a tighter range than the prediciton interval.
## The confidence bands get wider as you move away from the center of the line because the line is set to pivot on the central value and the slope of the line varys based on the sample selected
# Question 1.8
newdata <- data.frame(Bwt = c(2.8, 5, 10))
predict(catslm, newdata, interval = "confidence")
predict(catslm, newdata, interval = "predict")
## There is an issue in reporting the intervals for 5kg and 10kg.  In both cases there are no observations in our sample set with body weights greater than 3.9kg, therefore the model doesnt have sufficient information to predict the heart weight as the confidence interval is much wider.
# Question 2.1
catsbc <- boxCox(catslm)
# Question 2.2
lambda = catsbc$x[which(catsbc$y == max(catsbc$y))]
## Best lambda to use is 0.1
# Question 2.3
## Transform the data based on the optimal lambda
catsbcT <- (cats$Bwt^lambda - 1)/lambda
# Question 2.4
## Construct a new regression on the transformed data
catslmBC <- lm(catsbcT ~ cats$Hwt)
# Question 2.5
catsbcTran <- cbind(catsbcT, cats$Hwt)
plot(catsbcTran[,1], catsbcTran[,2], xlab = "Transformed Body weight", ylab = "Heart weight")
abline(catslmBC, lty = 2, col = "green")
catslmBC <- lm(catsbcT ~ cats$Hwt)
catsbcT <- (cats$Bwt^lambda - 1)/lambda
catsbc <- boxCox(catslm)
install.packages("MASS")
install.packages("MASS")
??boxCox
library(car)
catsbc <- boxCox(catslm)
# Question 2.2
lambda = catsbc$x[which(catsbc$y == max(catsbc$y))]
## Best lambda to use is 0.1
# Question 2.3
## Transform the data based on the optimal lambda
catsbcT <- (cats$Bwt^lambda - 1)/lambda
# Question 2.4
## Construct a new regression on the transformed data
catslmBC <- lm(catsbcT ~ cats$Hwt)
# Question 2.5
catsbcTran <- cbind(catsbcT, cats$Hwt)
plot(catsbcTran[,1], catsbcTran[,2], xlab = "Transformed Body weight", ylab = "Heart weight")
abline(catslmBC, lty = 2, col = "green")
abline(catslmBC, lty = 2, col = "green")
plot(catsbcTran[,1], catsbcTran[,2], xlab = "Transformed Body weight", ylab = "Heart weight")
abline(catslmBC, lty = 2, col = "green")
abline(catslmBC, lty = 2)
catslmBC
summary(catslmBC)
abline(catslmBC)
catsbc <- boxCox(catslm)
# Question 2.2
lambda = catsbc$x[which(catsbc$y == max(catsbc$y))]
## Best lambda to use is 0.1
# Question 2.3
catsbcT <- (cats$Hwt^lambda - 1)/lambda
catsbcT
catsbcT <- cats
catsbcT$Hwt <- (cats$Hwt^lambda - 1)/lambda
catslmBC <- lm(Hwt ~ Bwt, data = catsbcT)
plot(Hwt ~ Bwt, data = catsbcT, xlab = "Transformed Body weight", ylab = "Heart weight")
abline(catslmBC, lty = 2)
abline(catslmBC, lty = 2, col = "green")
summary(catslmBC)
plot(catslmBC)
catslmBC2 <- boxCox(catslmBC)
summary(catslmBC2)
catslmBC2
setwd("~/Dropbox/NYCDSA/Homework/20151008 - Multiple Linear Regression")
rest <- read.table('04NYCRestaurants.txt', header = TRUE, sep = " ", quote = "\"")
View(rest)
plot(price ~ ., data = rest, col = Location)
plot(rest$price ~ ., data = rest, col = Location)
rest <- read.table('04NYCRestaurants.txt', header = TRUE, sep = " ", quote = "\"")
plot(rest$price ~ ., data = rest, col = Location)
plot(price, data = rest, col = Location)
plot(Price ~ Food, data = rest, col = Location)
plot(Price ~ ., data = rest, col = Location)
rests <- read.table("04NYCRestaurants.txt", sep = " ", stringsAsFactors = FALSE, header = TRUE)
plot(rests[,2:5])
plot(rest$Price ~ ., data = rest, col = Location)
plot(rest[, 2:5], data = rest, col = Location)
plot(rest[, 2:5], data = rest, col = rest$Location)
#####2.1:
rest <- read.table('04NYCRestaurants.txt', header = TRUE, sep = " ", quote = "\"")
plot(rest[, 2:5], col = rest$Location)
restModFull <- lm(Price ~ ., data = rest)
restModFull
summary(restModFull)
rest <- read.table('04NYCRestaurants.txt', header = TRUE, sep = " ", quote = "\"", stringsAsFactors = FALSE)
plot(rest[, 2:5], col = rest$Location)
restModFull <- lm(Price ~ ., data = rest)
summary(restModFull)
View(rest)
restModFull <- lm(Price ~ . -Restaurant, data = rest)
summary(restModFull)
setwd("~/Dropbox/NYCDSA/Homework/20151008 - Multiple Linear Regression")
plot(restModFull)
library(car)
influencePlot(restModFull)
vif(restModFull)
plot(rest[, 2:5], col = rest$Location)
rest <- read.table('04NYCRestaurants.txt', header = TRUE, sep = " ", quote = "\"", stringsAsFactors = FALSE)
plot(rest[, 2:5], col = rest$Location)
rest$Location <- as.Factor(rest$Location)
rest$Location <- as.factor(rest$Location)
plot(rest[, 2:5], col = rest$Location)
avPlots(restModFull)
restModSvc <- lm(Price ~ Service, data = rest)
summary(restModSvc)
plot(Price ~ Service, data = rest)
abline(restModSvc)
abline(restModSvc, lty = 2)
plot(Price ~ Service, data = rest)
abline(restModSvc, lty = 2)
restModNew <- lm(Price ~ . -Restaurant -Service, data = rest)
summary(restModFull)
restModNew <- lm(Price ~ Food + Decor + Location, data = rest)
summary(restModFull)
restModNew <- lm(Price ~ . -Restaurant -Service, data = rest)
summary(restModNew)
plot(restModNew)
influencePlot(restModNew)
vif(restModNew)
avPlots(restModNew)
anova(restModNew, restModFull)
summary(anova(restModNew, restModFull))
anova(restModNew, restModFull)
restModFD <- lm(Price ~ Food + Decor, data = rest)
summary(restModFD)
plot(restModFD)
AIC(restModFull, restModNew, restModFD)
BIC(restModFull, restModNew, restModFD)
